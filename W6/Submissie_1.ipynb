{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Netwerkanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "privacy",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Notebook made by\n",
    "\n",
    "**Gebruik graag dit formaat**\n",
    "\n",
    "* Voor de namen:  voornaam rest van je naam, voornaam rest van je naam,....\n",
    "* je studentnummers: hetzelfde: scheidt met `,`\n",
    "* je emails: hetzelfde: scheidt met `,`\n",
    "* voor je groep: alleen de hoofdletter (dus voor de groep van Marx zou je `A` kiezen)\n",
    "\n",
    "__Namen__:Anoniem",
    "\n",
    "__Emails__:Anoniem",
    "\n",
    "__Student id__:Anoniem",
    "\n",
    "__Groep__:Anoniem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toelichting\n",
    "\n",
    "* De meeste opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. Dit zijn dus *NIET* alle tests, die komen er bij het graden nog bij.\n",
    "* Elke vraag is 1 punt waard, tenzij anders aangegeven. Soms is die punt onderverdeeld in deelpunten, maar niet altijd. \n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren\n",
    "\n",
    "## Na het inleveren!\n",
    "\n",
    "* Het gebeurt erg vaak dat mensen een \"leeg bestand\" inleveren. Vaak een andere versie van de opgave die nog ergens op je computer rondslingerde. Zonde van al je werk toch!\n",
    "* Dus, lever **minstens een half uur voor tijd in**. Download dan wat je hebt ingeleverd op Canvas. Geef het een andere naam om verwarring te voorkomen. En draai alle cellen, en bekijk het. Geen syntax fouten? Alle vragen gemaakt? Dan zit het vast wel goed, en hoef je niet in de zenuwen te zitten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd3ded8aee810700514967f470e4251c",
     "grade": false,
     "grade_id": "cell-29b47934d085ca5d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50e1ede8200b511b4d46cdfa44c40fd4",
     "grade": false,
     "grade_id": "cell-ef7fcbdc74fb7c74",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from nose.tools import assert_equal, assert_count_equal\n",
    "from numpy.testing import assert_almost_equal\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7213d5c3b3c20887a3955da648228a2",
     "grade": false,
     "grade_id": "FP",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# First Course: chap 3.3 Friendship Paradox\n",
    "\n",
    "1. Maak een netwerkx netwerk van Figuur 3.5.\n",
    "2. Waarom is de kans dat je Tom vindt met de \"random friend of picked person\" methode $\\frac{5}{21}$. Geef een heel helder antwoord.\n",
    "3. Programmeer de functie `kans_op_knoop(G,knoop)` die voor elk netwerk, voor elke knoop de kans berekent dat je die knoop trekt met de \"random friend of picked person\" methode.\n",
    "4. Schrijf een test die checked dat die kansen optellen tot 1.\n",
    "5. **Advanced** In de een na laatste paragraaf van 3.3 op blz 76 wordt een andere manier om die kansen te berekenen gemeld, die dezelfde uitkomst geeft. Programmeer die ook, en vergelijk de uitkomsten.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f730e7e5129c52cfcb119f834564e98b",
     "grade": false,
     "grade_id": "FPa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fig35=nx.Graph()\n",
    "nodes = ['Mary', 'Nancy', 'Tom', 'John','Pam', 'Bob', 'Tara']\n",
    "edges = [('Mary', 'Nancy'), ('Nancy', 'Tom'), ('Nancy', 'Bob'), ('Tom', 'John'), \n",
    "         ('Tom', 'Pam'), ('Tom', 'Bob'), ('John', 'Pam'), ('Bob', 'Tara')]\n",
    "Fig35.add_nodes_from(nodes)\n",
    "Fig35.add_edges_from(edges)\n",
    "\"\"\"\n",
    "De 5 / 21 kans is als volgt opgebouwd:\n",
    "Voor elke node berekenen we de kans dat deze node naar Tom leidt:\n",
    "Dit is voor elke node: 1 / len(G.nodes) * 1 / G.degree(node)\n",
    "Als een node geen verbinding heeft met Tom, is deze berekening 1 / len(G.nodes) * 0\n",
    "De berekening wordt in dit geval: 1/7*0+1/7*0+1/7*1/3+1/7*1/3+1/7*1/2+1/7*1/2 = 5/21\n",
    "De som nemen van al deze kansen komt dus uit op 5 / 21\n",
    "\"\"\" \n",
    "\n",
    "def kans_op_knoop(G, knoop):\n",
    "    chances = []\n",
    "    connected_with_node = G.neighbors(knoop)\n",
    "    for node in connected_with_node:\n",
    "        chance = (1 / len(G)) * (1 / G.degree(node))\n",
    "        chances.append(chance)\n",
    "    return sum(chances) \n",
    "\n",
    "def kans_op_knoop_alternatief(G, knoop):\n",
    "    chances = []\n",
    "    connected_with_node = G.neighbors(knoop)\n",
    "    for node in connected_with_node:\n",
    "        chance = 1 / G.degree(node)\n",
    "        chances.append(chance)\n",
    "    return sum(chances) / G.number_of_nodes()\n",
    "\n",
    "H= nx.karate_club_graph() \n",
    "# test\n",
    "sum(kans_op_knoop(H,x) for x in H)\n",
    "#kans_op_knoop(H,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "089bbe5ff2b275be4e29c0e2663f3145",
     "grade": true,
     "grade_id": "FPt",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Fig35, nx.Graph)\n",
    "H= nx.karate_club_graph()\n",
    "assert 0 <= kans_op_knoop(H,1)<= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First course\n",
    "\n",
    "Maak de sommen 3.11-3.24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8350197b9bcd5809dcfd53a673ba7ddf",
     "grade": true,
     "grade_id": "fc",
     "locked": false,
     "points": 14,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "3.11.a: Nodes 2 and 3. \\\n",
    "3.11.b: Nodes 2 and 5. \\\n",
    "3.11.c: Node 2. \\\n",
    "3.12: The graph would look like a star (A hub with a lot of connections and many nodes connected to that hub) \\\n",
    "3.13.1: No heavy-tailed distribution, because not a lot of people have a shoe size that is super above average. \\\n",
    "3.13.2: Heavy-tailed distibution, because a small amount of households has a way larger income than the median income. \\\n",
    "3.13.3: Heavy-tailed distribution, because a small amount of people have a degree that is way higher than the median degree (celebrities/politicians/etc) \\\n",
    "3.13.4: No heavy-tailed distribution, because this pairwise distance is usually really average. \\\n",
    "3.14: It would still be surprising, but less surprising than it would be without a heavy-tailed distribution.\n",
    "A heavy-tailed distribution means that there is a significant amount of outliers, but not necessarily higher or lower outliers. \\\n",
    "3.15.1: Approximately 100.000.000 pages \\\n",
    "3.15.2: Approximately 5.000.000 pages \\\n",
    "3.15.3: Approximately 10.000 pages \\\n",
    "3.16: ? max degree ? what it means ? if they have the same degree distribution ? why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f41e257c27c4187af417e8dd68a4a7c",
     "grade": true,
     "grade_id": "fc324",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "# 3.17\n",
    "filenameg='C:/Users/jesse/Desktop/NetworkScience/FirstCourseNetworkScience-master/datasets/openflights/openflights_world.edges.gz'\n",
    "G= nx.Graph()\n",
    "G = nx.read_edgelist(filenameg)\n",
    "\n",
    "#3.17.1\n",
    "routes = {node: G.degree(node) for node in G}\n",
    "average_num_routes = sum(routes.values()) / len(routes)\n",
    "# So the average number of routes served by each airport in 11.71.\n",
    "#3.17.2\n",
    "routes_top_5 = sorted(routes, key = routes.get, reverse = True)[:5]\n",
    "# So the top five airports in terms of number of routes are ['AMS', 'FRA', 'CDG', 'IST', 'ATL'].\n",
    "#3.17.3\n",
    "one_route_airports = [x[0] for x in routes.items() if x[1] == 1]\n",
    "amount_one_route_airports = len(one_route_airports)\n",
    "# So there are 709 airports that only serve one route.\n",
    "#3.17.4\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "highest_closeness_centrality = max(closeness_centrality, key = closeness_centrality.get)\n",
    "# So the airport with the highest closeness centrality is FRA\n",
    "#3.17.5\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "highest_betweenness_centrality = max(betweenness_centrality, key = betweenness_centrality.get)\n",
    "# So the airport with the highest betweenness centrality is CDG\n",
    "#3.17.6\n",
    "def heterogeneity_undirected(G):\n",
    "    degrees_only = [degree for node, degree in G.degree()]\n",
    "    degrees_squared = [degree**2 for degree in degrees_only]\n",
    "    degrees_squared_average = sum(degrees_squared) / len(degrees_squared)\n",
    "    degrees_average = sum(degrees_only) / len(degrees_only)\n",
    "    degrees_average_squared = degrees_average**2\n",
    "    heterogeneity = degrees_squared_average / degrees_average_squared\n",
    "    return heterogeneity\n",
    "# So the heterogeneity of this network is 5.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'in_degree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m filenameh\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../data/Week6/enwiki_math.edges.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m H\u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_edgelist(filenameh)\n\u001b[0;32m----> 4\u001b[0m in_degrees \u001b[38;5;241m=\u001b[39m {node: H\u001b[38;5;241m.\u001b[39min_degree(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m H}\n\u001b[1;32m      5\u001b[0m out_degrees \u001b[38;5;241m=\u001b[39m {node: H\u001b[38;5;241m.\u001b[39mout_degree(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m H}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#3.18.1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m filenameh\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../data/Week6/enwiki_math.edges.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m H\u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_edgelist(filenameh)\n\u001b[0;32m----> 4\u001b[0m in_degrees \u001b[38;5;241m=\u001b[39m {node: \u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_degree\u001b[49m(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m H}\n\u001b[1;32m      5\u001b[0m out_degrees \u001b[38;5;241m=\u001b[39m {node: H\u001b[38;5;241m.\u001b[39mout_degree(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m H}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#3.18.1\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'in_degree'"
     ]
    }
   ],
   "source": [
    "#3.18\n",
    "filenameh='../../../data/Week6/enwiki_math.edges.gz'\n",
    "H= nx.read_edgelist(filenameh)\n",
    "in_degrees = {node: H.in_degree(node) for node in H}\n",
    "out_degrees = {node: H.out_degree(node) for node in H}\n",
    "#3.18.1\n",
    "average_in_degree = sum(in_degrees.values()) / len(in_degrees)\n",
    "average_out_degree = sum(out_degrees.values()) / len(out_degrees)\n",
    "# The average in- and out-degree are equal (both 12.75). This means that the page has as many in-links as out-links.\n",
    "#3.18.2\n",
    "highest_in_degree = max(in_degrees, key = in_degrees.get)\n",
    "# So node '1152126' has the highest in_degree\n",
    "#3.18.3\n",
    "highest_out_degree = max(out_degrees, key = out_degrees.get)\n",
    "# So node '47738065' has the highest out_degree\n",
    "#3.18.4\n",
    "# The maximum in-degree is higher than the maximum out-degree. I won't expect this to be the case for many other web graphs,\n",
    "# since mathematics is very general and thus many current theories and ways things work relate back to mathematics. Other,\n",
    "# more specific pages will probably have a higher out-degree than in-degree, since not a lot of things relate back to\n",
    "# specific pages, but a specific page is probably based on a lot of general pages. \n",
    "#3.18.5\n",
    "def heterogeneity_directed_in(G):\n",
    "    in_degrees_only = [in_degree for node, in_degree in G.in_degree()]\n",
    "    in_degrees_squared = [in_degree**2 for in_degree in in_degrees_only]\n",
    "    in_degrees_squared_average = sum(in_degrees_squared) / len(in_degrees_squared)\n",
    "    in_degrees_average = sum(in_degrees_only) / len(in_degrees_only)\n",
    "    in_degrees_average_squared = in_degrees_average**2\n",
    "    in_heterogeneity = in_degrees_squared_average / in_degrees_average_squared\n",
    "    return in_heterogeneity\n",
    "# So the in_heterogeneity of this network is 38.21\n",
    "def heterogeneity_directed_out(G):\n",
    "    out_degrees_only = [out_degree for node, out_degree in G.out_degree()]\n",
    "    out_degrees_squared = [out_degree**2 for out_degree in out_degrees_only]\n",
    "    out_degrees_squared_average = sum(out_degrees_squared) / len(out_degrees_squared)\n",
    "    out_degrees_average = sum(out_degrees_only) / len(out_degrees_only)\n",
    "    out_degrees_average_squared = out_degrees_average**2\n",
    "    out_heterogeneity = out_degrees_squared_average / out_degrees_average_squared\n",
    "    return out_heterogeneity\n",
    "# So the out_heterogeneity of this network is 6.62\n",
    "\n",
    "#3.19\n",
    "def average_degree_neighbors(G, node):\n",
    "    neighbors = G.neighbors(node)\n",
    "    neighbor_degrees = [G.degree(neighbor) for neighbor in neighbors]\n",
    "    average_degree_neighbors = sum(neighbor_degrees) / len(neighbor_degrees)\n",
    "    return average_degree_neighbors\n",
    "\n",
    "#3.20\n",
    "# Yes, such networks would be assortative, meaning that nodes with similar degrees tend to be connected to each other\n",
    "# (high degrees to high degrees, low degrees to low degrees)\n",
    "\n",
    "#3.21.1\n",
    "# Networks with heavy-tailed degree distributions are more vulnerable to targeted attacks, since there is a lesser amount of\n",
    "# nodes with a high degree (these high degrees are extremely high, but there are not many nodes with such a high degree).\n",
    "# An attack on one of these nodes would be very damaging for a network.\n",
    "#3.21.2\n",
    "# A grid-like network will have a more steady and equal degree distribution, making it less vulnerable for attacks.\n",
    "# A targeted attack could still be more damaging than a random attack, since a node in a grid-like network\n",
    "# can play a big role in connected one node to another, since degrees will not be very high in such a network, meaning there\n",
    "# can be some crucial nodes that are the only ones forming a path between one and another node.\n",
    "#3.22\n",
    "# d, nodes with high betweenness centrality. A node with a high betweenness centrality is important for other nodes,\n",
    "# since it lies in a lot of shortests paths between two nodes. If such a node is removed, a lot of shortest paths\n",
    "# will become longer, thus increasing the average path length.\n",
    "#3.23\n",
    "# The one with a lower clustering coefficient would be a better target. Imagine node A and node B being the nodes\n",
    "# this assignment is about. node A and B both have degree 10, but every neighbor of node A is connected in some way\n",
    "# and none of the neighbors of node B are connected to each other, they are only connected to node B itself.\n",
    "# If node A is removed, the friend nodes will only disconnect from A \n",
    "# and will still be reachable from each other friend node of A.\n",
    "# If node B is removed, the friend nodes will disconnect from B and be disconnected from each other, forming 10 new subnetworks.\n",
    "# So removing the node with a lower clustering coefficient will disrupt the network more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
